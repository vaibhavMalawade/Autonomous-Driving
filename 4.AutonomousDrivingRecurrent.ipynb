{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Autonomous Driving (Part 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, the goal is to try different configurations for the assignment Autonomous Driving (Part 2).\n",
    "\n",
    "\n",
    "for learning to drive autonomously. For that reason, We will use the car racing example from [Gym](http://gym.openai.com). As we show in the last assignment, Gym is a framework for developing reinforcement learning approaches. It supports different types of agents. Here, we will focus on vehicles.\n",
    "\n",
    "*Important*: You need to install [Gym](http://gym.openai.com) in your system. The installation can be done with pip or by installing from the sources. More information at [https://gym.openai.com/docs/#installation](https://gym.openai.com/docs/#installation).\n",
    "\n",
    "*Important*: The Python version of Gym and the Python version of PyTorch has to be the same. This is an important requirement for making the inference pipeline function.\n",
    "\n",
    "Note that all scripts should be self-contained and executed on *any* machine that has required libraries installed.\n",
    "\n",
    "The solutions of the assignment can be delivered as Python Notebooks or .py files. The visual results can delivered as pdf- or image-files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, the trained model from the last assignment is necessary for performing different tests. The setups is the same where the car can turn left, right, accelerate or decelerate. The input is an image with 96x96 pixels. The test set is the same from Assignment 3, i.e. 1000 test consecutive frames. The 1000 test samples also include a maneuver.\n",
    " \n",
    "*Task Output*: Consider a model that is trained without data augmentation from Assignment 3. Test the model on 1000 consecutive test frames, each with a different scenario: 1. upside-down frame flip, 2. left-right frame flip and brown street color. You should generate three different videos (mp4) for each test scenario. We recommend the library _cv2_ to generate the videos. On the first case all 1000 frames should flipped upside-down, on the second case all 1000 frames should flipped left-right and final on the last case the road should be painted brown for all 1000 frames. The deliverable of theb exercise are the average test accuracy per scenario plus three videos highlighting driving the car in each test scenario.\n",
    "\n",
    "*Important*: The scripts should be **self-contained**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(r'E:\\MLSP\\Lab\\training_data.npz')\n",
    "image = data['frames']\n",
    "labels = data['controls']\n",
    "\n",
    "train_size = labels.shape[0]\n",
    "\n",
    "train_size = train_size - 1000\n",
    "\n",
    "test_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = image[:1000]\n",
    "test_labels = labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scenario:\n",
    "    def __init__(self, images , labels, upside_down=False , left_right=False, brown_street = False):\n",
    "        self.image = images\n",
    "        self.labels = labels\n",
    "        self.upside_down = upside_down\n",
    "        self.left_right = left_right\n",
    "        self.brown_street = brown_street\n",
    "        self.to_tensor = transforms.ToTensor() \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #image = Image.fromarray(self.image[idx])\n",
    "\n",
    "        image = self.image[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.upside_down:\n",
    "             image = cv2.flip(image, 0)\n",
    "            \n",
    "\n",
    "        elif self.left_right:\n",
    "            image = cv2.flip(image,1)\n",
    "            if (label == np.array([0, 0, 1, 0, 0])).all():\n",
    "              label = [0,0,0,1,0]\n",
    "            if (label == np.array([0, 0, 0, 1, 0])).all():\n",
    "              label = [0,0,1,0,0]\n",
    "\n",
    "            \n",
    "\n",
    "        elif self.brown_street:\n",
    "            def is_gray(pixel, tolerance=10, black_threshold=20):\n",
    "                # Check if the pixel is close to gray\n",
    "                gray_condition = abs(pixel[0] - pixel[1]) < tolerance and abs(pixel[1] - pixel[2]) < tolerance and abs(pixel[0] - pixel[2]) < tolerance\n",
    "                \n",
    "                # Check if the pixel is not black\n",
    "                not_black_condition = all(value > black_threshold for value in pixel)\n",
    "                \n",
    "                return gray_condition and not_black_condition\n",
    "            \n",
    "            gray_pixels = np.apply_along_axis(is_gray, 2, image)\n",
    "\n",
    "            image[gray_pixels] = [101, 67, 33]\n",
    "\n",
    "        image = Image.fromarray(image)\n",
    "        image = self.to_tensor(image)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return image , label\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_upside_down = scenario(test_images , test_labels, upside_down=True , left_right=False, brown_street = False)\n",
    "dataset_left_right = scenario(test_images , test_labels, upside_down=False , left_right=True, brown_street = False)\n",
    "dataset_brown_street = scenario(test_images , test_labels, upside_down=False , left_right=False, brown_street = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'tensor([0, 0, 0, 0, 1])')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "imu, label = dataset_left_right[236]\n",
    "imu = imu.permute(1, 2, 0).numpy() \n",
    "imu = (imu * 255).astype(np.uint8)\n",
    "\n",
    "plt.imshow(imu)\n",
    "plt.title(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_upside_down = DataLoader(dataset_upside_down, batch_size =30, shuffle = False)\n",
    "dataloader_left_right = DataLoader(dataset_left_right, batch_size =30, shuffle = False)\n",
    "dataloader_brown_street = DataLoader(dataset_brown_street, batch_size =30, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CarRacingCNN(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(CarRacingCNN, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 12 * 12, 512)\n",
    "        self.fc2 = nn.Linear(512, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 128 * 12 * 12)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = CarRacingCNN(input_channels=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Move model to the appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test_loader, flip):\n",
    "    model.load_state_dict(torch.load('best_aug_model.pt'))\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image= image.to(device) \n",
    "            label = torch.argmax(label, dim=1).to(device).long()\n",
    "\n",
    "            outputs = model(image)\n",
    "            loss = criterion(outputs, label)\n",
    "            test_loss += loss.item() * image.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == label).sum().item()\n",
    "\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_accuracy = correct / len(test_loader.dataset)\n",
    "    print('Test loss for {} is {}'.format( flip, test_loss ,))\n",
    "    print('Test Accuray for {} is {}'.format( flip, test_accuracy))\n",
    "\n",
    "    return test_loss , test_accuracy\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43maccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader_upside_down\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflip\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mupside_down\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 13\u001b[0m, in \u001b[0;36maccuracy\u001b[1;34m(test_loader, flip)\u001b[0m\n\u001b[0;32m     10\u001b[0m image\u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mto(device) \n\u001b[0;32m     11\u001b[0m label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(label, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m---> 13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, label)\n\u001b[0;32m     15\u001b[0m test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m image\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32me:\\MLSP\\Lab\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\MLSP\\Lab\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 17\u001b[0m, in \u001b[0;36mCarRacingCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x))\n\u001b[1;32m---> 17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmax_pool2d(x, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32me:\\MLSP\\Lab\\venv\\lib\\site-packages\\torch\\_jit_internal.py:497\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\MLSP\\Lab\\venv\\lib\\site-packages\\torch\\nn\\functional.py:796\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    795\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[1;32m--> 796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy(dataloader_upside_down , flip = 'upside_down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss for lef to right is 0.5416203694418072\n",
      "Test Accuray for lef to right is 0.726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5416203694418072, 0.726)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(dataloader_left_right , flip = 'lef to right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12720\\278352964.py:35: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  gray_condition = abs(pixel[0] - pixel[1]) < tolerance and abs(pixel[1] - pixel[2]) < tolerance and abs(pixel[0] - pixel[2]) < tolerance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss for brow_street is 0.46142654582858084\n",
      "Test Accuray for brow_street is 0.822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.46142654582858084, 0.822)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(dataloader_brown_street , flip = 'brow_street')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 96])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_upside_down[0][0].shape[1:]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12720\\278352964.py:35: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  gray_condition = abs(pixel[0] - pixel[1]) < tolerance and abs(pixel[1] - pixel[2]) < tolerance and abs(pixel[0] - pixel[2]) < tolerance\n"
     ]
    }
   ],
   "source": [
    "def create_video_from_dataset(dataset, output_path, frame_rate=30):\n",
    "    # Assuming images are RGB, get the height, width, and number of channels from the first image\n",
    "    \n",
    "    height, width = dataset[0][0].shape[1:]\n",
    "    size = (width, height)\n",
    "\n",
    "    # Initialize video writer with MP4 codec\n",
    "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), frame_rate, size)\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        image, label = dataset[i]\n",
    "        image = image.permute(1, 2, 0).numpy()  # Convert from torch tensor to numpy array\n",
    "        image = (image * 255).astype(np.uint8)  # Convert to uint8 type\n",
    "\n",
    "        # OpenCV expects BGR images, convert RGB to BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Write frame to video\n",
    "        out.write(image)\n",
    "\n",
    "    out.release()\n",
    "\n",
    "# Create videos for each dataset\n",
    "create_video_from_dataset(dataset_upside_down, 'upside_down_video.mp4')\n",
    "create_video_from_dataset(dataset_left_right, 'left_right_video.mp4')\n",
    "create_video_from_dataset(dataset_brown_street, 'brown_street_video.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Autonomous Driving"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, the trained model from the last assignment is necessary for end-to-end driving. The goal is to use the neural network to drive the car whitin the simulator. For the reason, both programs have to executed under the same python script. The simulator will provide with input data the neural network, while the neural network will provide the action to the simulator. Note: if the neural network is not able to drive in the simulator, you might need to retrain the model with more data.\n",
    " \n",
    "*Task Output*: Consider a model that is trained with the data augmentation from Assignment 3. Integrate the simulator in the inference script of the model. The output of the exercise is to launch the simulator and let the neural network perform the driving. This should be a live demo.\n",
    "\n",
    "*Important*: The scripts should be **self-contained**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EnhancedCarRacingCNN(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(EnhancedCarRacingCNN, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "\n",
    "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.fc1 = nn.Linear(512 * 6 * 6, 1024)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 512 * 6 * 6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = CarRacingCNNWithAttention(input_channels=3)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1]\n",
      "[0.  0.5 0. ]\n",
      "\n",
      "action ['+0.00', '+0.50', '+0.00']\n",
      "step 0 total_reward +6.31\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0.  0.5 0. ]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0 0 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n",
      "\n",
      "action ['+0.00', '+0.00', '+0.80']\n",
      "step 200 total_reward +44.00\n",
      "[0, 1, 0, 0, 0]\n",
      "[0.  0.  0.8]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from typing import Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.envs.box2d.car_dynamics import Car\n",
    "from gym.error import DependencyNotInstalled, InvalidAction\n",
    "from gym.utils import EzPickle\n",
    "\n",
    "model.load_state_dict(torch.load('best_aug_model1.pt'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "try:\n",
    "    import Box2D\n",
    "    from Box2D.b2 import contactListener, fixtureDef, polygonShape\n",
    "except ImportError:\n",
    "    raise DependencyNotInstalled(\"box2D is not installed, run `pip install gym[box2d]`\")\n",
    "\n",
    "try:\n",
    "    # As pygame is necessary for using the environment (reset and step) even without a render mode\n",
    "    #   therefore, pygame is a necessary import for the environment.\n",
    "    import pygame\n",
    "    from pygame import gfxdraw\n",
    "except ImportError:\n",
    "    raise DependencyNotInstalled(\n",
    "        \"pygame is not installed, run `pip install gym[box2d]`\"\n",
    "    )\n",
    "\n",
    "\n",
    "STATE_W = 96  # less than Atari 160x192\n",
    "STATE_H = 96\n",
    "VIDEO_W = 600\n",
    "VIDEO_H = 400\n",
    "WINDOW_W = 1000\n",
    "WINDOW_H = 800\n",
    "\n",
    "SCALE = 6.0  # Track scale\n",
    "TRACK_RAD = 900 / SCALE  # Track is heavily morphed circle with this radius\n",
    "PLAYFIELD = 2000 / SCALE  # Game over boundary\n",
    "FPS = 50  # Frames per second\n",
    "ZOOM = 2.7  # Camera zoom\n",
    "ZOOM_FOLLOW = True  # Set to False for fixed view (don't use zoom)\n",
    "\n",
    "\n",
    "TRACK_DETAIL_STEP = 21 / SCALE\n",
    "TRACK_TURN_RATE = 0.31\n",
    "TRACK_WIDTH = 40 / SCALE\n",
    "BORDER = 8 / SCALE\n",
    "BORDER_MIN_COUNT = 4\n",
    "GRASS_DIM = PLAYFIELD / 20.0\n",
    "MAX_SHAPE_DIM = (\n",
    "    max(GRASS_DIM, TRACK_WIDTH, TRACK_DETAIL_STEP) * math.sqrt(2) * ZOOM * SCALE\n",
    ")\n",
    "\n",
    "\n",
    "class FrictionDetector(contactListener):\n",
    "    def __init__(self, env, lap_complete_percent):\n",
    "        contactListener.__init__(self)\n",
    "        self.env = env\n",
    "        self.lap_complete_percent = lap_complete_percent\n",
    "\n",
    "    def BeginContact(self, contact):\n",
    "        self._contact(contact, True)\n",
    "\n",
    "    def EndContact(self, contact):\n",
    "        self._contact(contact, False)\n",
    "\n",
    "    def _contact(self, contact, begin):\n",
    "        tile = None\n",
    "        obj = None\n",
    "        u1 = contact.fixtureA.body.userData\n",
    "        u2 = contact.fixtureB.body.userData\n",
    "        if u1 and \"road_friction\" in u1.__dict__:\n",
    "            tile = u1\n",
    "            obj = u2\n",
    "        if u2 and \"road_friction\" in u2.__dict__:\n",
    "            tile = u2\n",
    "            obj = u1\n",
    "        if not tile:\n",
    "            return\n",
    "\n",
    "        # inherit tile color from env\n",
    "        tile.color[:] = self.env.road_color\n",
    "        if not obj or \"tiles\" not in obj.__dict__:\n",
    "            return\n",
    "        if begin:\n",
    "            obj.tiles.add(tile)\n",
    "            if not tile.road_visited:\n",
    "                tile.road_visited = True\n",
    "                self.env.reward += 1000.0 / len(self.env.track)\n",
    "                self.env.tile_visited_count += 1\n",
    "\n",
    "                # Lap is considered completed if enough % of the track was covered\n",
    "                if (\n",
    "                    tile.idx == 0\n",
    "                    and self.env.tile_visited_count / len(self.env.track)\n",
    "                    > self.lap_complete_percent\n",
    "                ):\n",
    "                    self.env.new_lap = True\n",
    "        else:\n",
    "            obj.tiles.remove(tile)\n",
    "\n",
    "\n",
    "class CarRacing(gym.Env, EzPickle):\n",
    "    \"\"\"\n",
    "    ### Description\n",
    "    The easiest control task to learn from pixels - a top-down\n",
    "    racing environment. The generated track is random every episode.\n",
    "\n",
    "    Some indicators are shown at the bottom of the window along with the\n",
    "    state RGB buffer. From left to right: true speed, four ABS sensors,\n",
    "    steering wheel position, and gyroscope.\n",
    "    To play yourself (it's rather fast for humans), type:\n",
    "    ```\n",
    "    python gym/envs/box2d/car_racing.py\n",
    "    ```\n",
    "    Remember: it's a powerful rear-wheel drive car - don't press the accelerator\n",
    "    and turn at the same time.\n",
    "\n",
    "    ### Action Space\n",
    "    If continuous:\n",
    "        There are 3 actions: steering (-1 is full left, +1 is full right), gas, and breaking.\n",
    "    If discrete:\n",
    "        There are 5 actions: do nothing, steer left, steer right, gas, brake.\n",
    "\n",
    "    ### Observation Space\n",
    "    State consists of 96x96 pixels.\n",
    "\n",
    "    ### Rewards\n",
    "    The reward is -0.1 every frame and +1000/N for every track tile visited,\n",
    "    where N is the total number of tiles visited in the track. For example,\n",
    "    if you have finished in 732 frames, your reward is\n",
    "    1000 - 0.1*732 = 926.8 points.\n",
    "\n",
    "    ### Starting State\n",
    "    The car starts at rest in the center of the road.\n",
    "\n",
    "    ### Episode Termination\n",
    "    The episode finishes when all of the tiles are visited. The car can also go\n",
    "    outside of the playfield - that is, far off the track, in which case it will\n",
    "    receive -100 reward and die.\n",
    "\n",
    "    ### Arguments\n",
    "    `lap_complete_percent` dictates the percentage of tiles that must be visited by\n",
    "    the agent before a lap is considered complete.\n",
    "\n",
    "    Passing `domain_randomize=True` enables the domain randomized variant of the environment.\n",
    "    In this scenario, the background and track colours are different on every reset.\n",
    "\n",
    "    Passing `continuous=False` converts the environment to use discrete action space.\n",
    "    The discrete action space has 5 actions: [do nothing, left, right, gas, brake].\n",
    "\n",
    "    ### Reset Arguments\n",
    "    Passing the option `options[\"randomize\"] = True` will change the current colour of the environment on demand.\n",
    "    Correspondingly, passing the option `options[\"randomize\"] = False` will not change the current colour of the environment.\n",
    "    `domain_randomize` must be `True` on init for this argument to work.\n",
    "    Example usage:\n",
    "    ```py\n",
    "        env = gym.make(\"CarRacing-v1\", domain_randomize=True)\n",
    "\n",
    "        # normal reset, this changes the colour scheme by default\n",
    "        env.reset()\n",
    "\n",
    "        # reset with colour scheme change\n",
    "        env.reset(options={\"randomize\": True})\n",
    "\n",
    "        # reset with no colour scheme change\n",
    "        env.reset(options={\"randomize\": False})\n",
    "    ```\n",
    "\n",
    "    ### Version History\n",
    "    - v1: Change track completion logic and add domain randomization (0.24.0)\n",
    "    - v0: Original version\n",
    "\n",
    "    ### References\n",
    "    - Chris Campbell (2014), http://www.iforce2d.net/b2dtut/top-down-car.\n",
    "\n",
    "    ### Credits\n",
    "    Created by Oleg Klimov\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\n",
    "        \"render_modes\": [\n",
    "            \"human\",\n",
    "            \"rgb_array\",\n",
    "            \"state_pixels\",\n",
    "        ],\n",
    "        \"render_fps\": FPS,\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        render_mode: Optional[str] = None,\n",
    "        verbose: bool = False,\n",
    "        lap_complete_percent: float = 0.95,\n",
    "        domain_randomize: bool = False,\n",
    "        continuous: bool = True,\n",
    "    ):\n",
    "        EzPickle.__init__(\n",
    "            self,\n",
    "            render_mode,\n",
    "            verbose,\n",
    "            lap_complete_percent,\n",
    "            domain_randomize,\n",
    "            continuous,\n",
    "        )\n",
    "        self.continuous = continuous\n",
    "        self.domain_randomize = domain_randomize\n",
    "        self.lap_complete_percent = lap_complete_percent\n",
    "        self._init_colors()\n",
    "\n",
    "        self.contactListener_keepref = FrictionDetector(self, self.lap_complete_percent)\n",
    "        self.world = Box2D.b2World((0, 0), contactListener=self.contactListener_keepref)\n",
    "        self.screen: Optional[pygame.Surface] = None\n",
    "        self.surf = None\n",
    "        self.clock = None\n",
    "        self.isopen = True\n",
    "        self.invisible_state_window = None\n",
    "        self.invisible_video_window = None\n",
    "        self.road = None\n",
    "        self.car: Optional[Car] = None\n",
    "        self.reward = 0.0\n",
    "        self.prev_reward = 0.0\n",
    "        self.verbose = verbose\n",
    "        self.new_lap = False\n",
    "        self.fd_tile = fixtureDef(\n",
    "            shape=polygonShape(vertices=[(0, 0), (1, 0), (1, -1), (0, -1)])\n",
    "        )\n",
    "\n",
    "        # This will throw a warning in tests/envs/test_envs in utils/env_checker.py as the space is not symmetric\n",
    "        #   or normalised however this is not possible here so ignore\n",
    "        if self.continuous:\n",
    "            self.action_space = spaces.Box(\n",
    "                np.array([-1, 0, 0]).astype(np.float32),\n",
    "                np.array([+1, +1, +1]).astype(np.float32),\n",
    "            )  # steer, gas, brake\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(5)\n",
    "            # do nothing, left, right, gas, brake\n",
    "\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=255, shape=(STATE_H, STATE_W, 3), dtype=np.uint8\n",
    "        )\n",
    "\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "    def _destroy(self):\n",
    "        if not self.road:\n",
    "            return\n",
    "        for t in self.road:\n",
    "            self.world.DestroyBody(t)\n",
    "        self.road = []\n",
    "        assert self.car is not None\n",
    "        self.car.destroy()\n",
    "\n",
    "    def _init_colors(self):\n",
    "        if self.domain_randomize:\n",
    "            # domain randomize the bg and grass colour\n",
    "            self.road_color = self.np_random.uniform(0, 210, size=3)\n",
    "\n",
    "            self.bg_color = self.np_random.uniform(0, 210, size=3)\n",
    "\n",
    "            self.grass_color = np.copy(self.bg_color)\n",
    "            idx = self.np_random.integers(3)\n",
    "            self.grass_color[idx] += 20\n",
    "        else:\n",
    "            # default colours\n",
    "            self.road_color = np.array([102, 102, 102])\n",
    "            self.bg_color = np.array([102, 204, 102])\n",
    "            self.grass_color = np.array([102, 230, 102])\n",
    "\n",
    "    def _reinit_colors(self, randomize):\n",
    "        assert (\n",
    "            self.domain_randomize\n",
    "        ), \"domain_randomize must be True to use this function.\"\n",
    "\n",
    "        if randomize:\n",
    "            # domain randomize the bg and grass colour\n",
    "            self.road_color = self.np_random.uniform(0, 210, size=3)\n",
    "\n",
    "            self.bg_color = self.np_random.uniform(0, 210, size=3)\n",
    "\n",
    "            self.grass_color = np.copy(self.bg_color)\n",
    "            idx = self.np_random.integers(3)\n",
    "            self.grass_color[idx] += 20\n",
    "\n",
    "    def _create_track(self):\n",
    "        CHECKPOINTS = 12\n",
    "\n",
    "        # Create checkpoints\n",
    "        checkpoints = []\n",
    "        for c in range(CHECKPOINTS):\n",
    "            noise = self.np_random.uniform(0, 2 * math.pi * 1 / CHECKPOINTS)\n",
    "            alpha = 2 * math.pi * c / CHECKPOINTS + noise\n",
    "            rad = self.np_random.uniform(TRACK_RAD / 3, TRACK_RAD)\n",
    "\n",
    "            if c == 0:\n",
    "                alpha = 0\n",
    "                rad = 1.5 * TRACK_RAD\n",
    "            if c == CHECKPOINTS - 1:\n",
    "                alpha = 2 * math.pi * c / CHECKPOINTS\n",
    "                self.start_alpha = 2 * math.pi * (-0.5) / CHECKPOINTS\n",
    "                rad = 1.5 * TRACK_RAD\n",
    "\n",
    "            checkpoints.append((alpha, rad * math.cos(alpha), rad * math.sin(alpha)))\n",
    "        self.road = []\n",
    "\n",
    "        # Go from one checkpoint to another to create track\n",
    "        x, y, beta = 1.5 * TRACK_RAD, 0, 0\n",
    "        dest_i = 0\n",
    "        laps = 0\n",
    "        track = []\n",
    "        no_freeze = 2500\n",
    "        visited_other_side = False\n",
    "        while True:\n",
    "            alpha = math.atan2(y, x)\n",
    "            if visited_other_side and alpha > 0:\n",
    "                laps += 1\n",
    "                visited_other_side = False\n",
    "            if alpha < 0:\n",
    "                visited_other_side = True\n",
    "                alpha += 2 * math.pi\n",
    "\n",
    "            while True:  # Find destination from checkpoints\n",
    "                failed = True\n",
    "\n",
    "                while True:\n",
    "                    dest_alpha, dest_x, dest_y = checkpoints[dest_i % len(checkpoints)]\n",
    "                    if alpha <= dest_alpha:\n",
    "                        failed = False\n",
    "                        break\n",
    "                    dest_i += 1\n",
    "                    if dest_i % len(checkpoints) == 0:\n",
    "                        break\n",
    "\n",
    "                if not failed:\n",
    "                    break\n",
    "\n",
    "                alpha -= 2 * math.pi\n",
    "                continue\n",
    "\n",
    "            r1x = math.cos(beta)\n",
    "            r1y = math.sin(beta)\n",
    "            p1x = -r1y\n",
    "            p1y = r1x\n",
    "            dest_dx = dest_x - x  # vector towards destination\n",
    "            dest_dy = dest_y - y\n",
    "            # destination vector projected on rad:\n",
    "            proj = r1x * dest_dx + r1y * dest_dy\n",
    "            while beta - alpha > 1.5 * math.pi:\n",
    "                beta -= 2 * math.pi\n",
    "            while beta - alpha < -1.5 * math.pi:\n",
    "                beta += 2 * math.pi\n",
    "            prev_beta = beta\n",
    "            proj *= SCALE\n",
    "            if proj > 0.3:\n",
    "                beta -= min(TRACK_TURN_RATE, abs(0.001 * proj))\n",
    "            if proj < -0.3:\n",
    "                beta += min(TRACK_TURN_RATE, abs(0.001 * proj))\n",
    "            x += p1x * TRACK_DETAIL_STEP\n",
    "            y += p1y * TRACK_DETAIL_STEP\n",
    "            track.append((alpha, prev_beta * 0.5 + beta * 0.5, x, y))\n",
    "            if laps > 4:\n",
    "                break\n",
    "            no_freeze -= 1\n",
    "            if no_freeze == 0:\n",
    "                break\n",
    "\n",
    "        # Find closed loop range i1..i2, first loop should be ignored, second is OK\n",
    "        i1, i2 = -1, -1\n",
    "        i = len(track)\n",
    "        while True:\n",
    "            i -= 1\n",
    "            if i == 0:\n",
    "                return False  # Failed\n",
    "            pass_through_start = (\n",
    "                track[i][0] > self.start_alpha and track[i - 1][0] <= self.start_alpha\n",
    "            )\n",
    "            if pass_through_start and i2 == -1:\n",
    "                i2 = i\n",
    "            elif pass_through_start and i1 == -1:\n",
    "                i1 = i\n",
    "                break\n",
    "        if self.verbose:\n",
    "            print(\"Track generation: %i..%i -> %i-tiles track\" % (i1, i2, i2 - i1))\n",
    "        assert i1 != -1\n",
    "        assert i2 != -1\n",
    "\n",
    "        track = track[i1 : i2 - 1]\n",
    "\n",
    "        first_beta = track[0][1]\n",
    "        first_perp_x = math.cos(first_beta)\n",
    "        first_perp_y = math.sin(first_beta)\n",
    "        # Length of perpendicular jump to put together head and tail\n",
    "        well_glued_together = np.sqrt(\n",
    "            np.square(first_perp_x * (track[0][2] - track[-1][2]))\n",
    "            + np.square(first_perp_y * (track[0][3] - track[-1][3]))\n",
    "        )\n",
    "        if well_glued_together > TRACK_DETAIL_STEP:\n",
    "            return False\n",
    "\n",
    "        # Red-white border on hard turns\n",
    "        border = [False] * len(track)\n",
    "        for i in range(len(track)):\n",
    "            good = True\n",
    "            oneside = 0\n",
    "            for neg in range(BORDER_MIN_COUNT):\n",
    "                beta1 = track[i - neg - 0][1]\n",
    "                beta2 = track[i - neg - 1][1]\n",
    "                good &= abs(beta1 - beta2) > TRACK_TURN_RATE * 0.2\n",
    "                oneside += np.sign(beta1 - beta2)\n",
    "            good &= abs(oneside) == BORDER_MIN_COUNT\n",
    "            border[i] = good\n",
    "        for i in range(len(track)):\n",
    "            for neg in range(BORDER_MIN_COUNT):\n",
    "                border[i - neg] |= border[i]\n",
    "\n",
    "        # Create tiles\n",
    "        for i in range(len(track)):\n",
    "            alpha1, beta1, x1, y1 = track[i]\n",
    "            alpha2, beta2, x2, y2 = track[i - 1]\n",
    "            road1_l = (\n",
    "                x1 - TRACK_WIDTH * math.cos(beta1),\n",
    "                y1 - TRACK_WIDTH * math.sin(beta1),\n",
    "            )\n",
    "            road1_r = (\n",
    "                x1 + TRACK_WIDTH * math.cos(beta1),\n",
    "                y1 + TRACK_WIDTH * math.sin(beta1),\n",
    "            )\n",
    "            road2_l = (\n",
    "                x2 - TRACK_WIDTH * math.cos(beta2),\n",
    "                y2 - TRACK_WIDTH * math.sin(beta2),\n",
    "            )\n",
    "            road2_r = (\n",
    "                x2 + TRACK_WIDTH * math.cos(beta2),\n",
    "                y2 + TRACK_WIDTH * math.sin(beta2),\n",
    "            )\n",
    "            vertices = [road1_l, road1_r, road2_r, road2_l]\n",
    "            self.fd_tile.shape.vertices = vertices\n",
    "            t = self.world.CreateStaticBody(fixtures=self.fd_tile)\n",
    "            t.userData = t\n",
    "            c = 0.01 * (i % 3) * 255\n",
    "            t.color = self.road_color + c\n",
    "            t.road_visited = False\n",
    "            t.road_friction = 1.0\n",
    "            t.idx = i\n",
    "            t.fixtures[0].sensor = True\n",
    "            self.road_poly.append(([road1_l, road1_r, road2_r, road2_l], t.color))\n",
    "            self.road.append(t)\n",
    "            if border[i]:\n",
    "                side = np.sign(beta2 - beta1)\n",
    "                b1_l = (\n",
    "                    x1 + side * TRACK_WIDTH * math.cos(beta1),\n",
    "                    y1 + side * TRACK_WIDTH * math.sin(beta1),\n",
    "                )\n",
    "                b1_r = (\n",
    "                    x1 + side * (TRACK_WIDTH + BORDER) * math.cos(beta1),\n",
    "                    y1 + side * (TRACK_WIDTH + BORDER) * math.sin(beta1),\n",
    "                )\n",
    "                b2_l = (\n",
    "                    x2 + side * TRACK_WIDTH * math.cos(beta2),\n",
    "                    y2 + side * TRACK_WIDTH * math.sin(beta2),\n",
    "                )\n",
    "                b2_r = (\n",
    "                    x2 + side * (TRACK_WIDTH + BORDER) * math.cos(beta2),\n",
    "                    y2 + side * (TRACK_WIDTH + BORDER) * math.sin(beta2),\n",
    "                )\n",
    "                self.road_poly.append(\n",
    "                    (\n",
    "                        [b1_l, b1_r, b2_r, b2_l],\n",
    "                        (255, 255, 255) if i % 2 == 0 else (255, 0, 0),\n",
    "                    )\n",
    "                )\n",
    "        self.track = track\n",
    "        return True\n",
    "\n",
    "    def reset(\n",
    "        self,\n",
    "        *,\n",
    "        seed: Optional[int] = None,\n",
    "        options: Optional[dict] = None,\n",
    "    ):\n",
    "        super().reset(seed=seed)\n",
    "        self._destroy()\n",
    "        self.world.contactListener_bug_workaround = FrictionDetector(\n",
    "            self, self.lap_complete_percent\n",
    "        )\n",
    "        self.world.contactListener = self.world.contactListener_bug_workaround\n",
    "        self.reward = 0.0\n",
    "        self.prev_reward = 0.0\n",
    "        self.tile_visited_count = 0\n",
    "        self.t = 0.0\n",
    "        self.new_lap = False\n",
    "        self.road_poly = []\n",
    "\n",
    "        if self.domain_randomize:\n",
    "            randomize = True\n",
    "            if isinstance(options, dict):\n",
    "                if \"randomize\" in options:\n",
    "                    randomize = options[\"randomize\"]\n",
    "\n",
    "            self._reinit_colors(randomize)\n",
    "\n",
    "        while True:\n",
    "            success = self._create_track()\n",
    "            if success:\n",
    "                break\n",
    "            if self.verbose:\n",
    "                print(\n",
    "                    \"retry to generate track (normal if there are not many\"\n",
    "                    \"instances of this message)\"\n",
    "                )\n",
    "        self.car = Car(self.world, *self.track[0][1:4])\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return self.step(None)[0], {}\n",
    "\n",
    "    def step(self, action: Union[np.ndarray, int]):\n",
    "        assert self.car is not None\n",
    "        if action is not None:\n",
    "            if self.continuous:\n",
    "                self.car.steer(-action[0])\n",
    "                self.car.gas(action[1])\n",
    "                self.car.brake(action[2])\n",
    "            else:\n",
    "                if not self.action_space.contains(action):\n",
    "                    raise InvalidAction(\n",
    "                        f\"you passed the invalid action `{action}`. \"\n",
    "                        f\"The supported action_space is `{self.action_space}`\"\n",
    "                    )\n",
    "                self.car.steer(-0.6 * (action == 1) + 0.6 * (action == 2))\n",
    "                self.car.gas(0.2 * (action == 3))\n",
    "                self.car.brake(0.8 * (action == 4))\n",
    "\n",
    "        self.car.step(1.0 / FPS)\n",
    "        self.world.Step(1.0 / FPS, 6 * 30, 2 * 30)\n",
    "        self.t += 1.0 / FPS\n",
    "\n",
    "        self.state = self._render(\"state_pixels\")\n",
    "\n",
    "        step_reward = 0\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        if action is not None:  # First step without action, called from reset()\n",
    "            self.reward -= 0.1\n",
    "            # We actually don't want to count fuel spent, we want car to be faster.\n",
    "            # self.reward -=  10 * self.car.fuel_spent / ENGINE_POWER\n",
    "            self.car.fuel_spent = 0.0\n",
    "            step_reward = self.reward - self.prev_reward\n",
    "            self.prev_reward = self.reward\n",
    "            if self.tile_visited_count == len(self.track) or self.new_lap:\n",
    "                # Truncation due to finishing lap\n",
    "                # This should not be treated as a failure\n",
    "                # but like a timeout\n",
    "                truncated = True\n",
    "            x, y = self.car.hull.position\n",
    "            if abs(x) > PLAYFIELD or abs(y) > PLAYFIELD:\n",
    "                terminated = True\n",
    "                step_reward = -100\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return self.state, step_reward, terminated, truncated, {}\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode is None:\n",
    "            gym.logger.warn(\n",
    "                \"You are calling render method without specifying any render mode. \"\n",
    "                \"You can specify the render_mode at initialization, \"\n",
    "                f'e.g. gym(\"{self.spec.id}\", render_mode=\"rgb_array\")'\n",
    "            )\n",
    "        else:\n",
    "            return self._render(self.render_mode)\n",
    "\n",
    "    def _render(self, mode: str):\n",
    "        assert mode in self.metadata[\"render_modes\"]\n",
    "\n",
    "        pygame.font.init()\n",
    "        if self.screen is None and mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.screen = pygame.display.set_mode((WINDOW_W, WINDOW_H))\n",
    "        if self.clock is None:\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        if \"t\" not in self.__dict__:\n",
    "            return  # reset() not called yet\n",
    "\n",
    "        self.surf = pygame.Surface((WINDOW_W, WINDOW_H))\n",
    "\n",
    "        assert self.car is not None\n",
    "        # computing transformations\n",
    "        angle = -self.car.hull.angle\n",
    "        # Animating first second zoom.\n",
    "        zoom = 0.1 * SCALE * max(1 - self.t, 0) + ZOOM * SCALE * min(self.t, 1)\n",
    "        scroll_x = -(self.car.hull.position[0]) * zoom\n",
    "        scroll_y = -(self.car.hull.position[1]) * zoom\n",
    "        trans = pygame.math.Vector2((scroll_x, scroll_y)).rotate_rad(angle)\n",
    "        trans = (WINDOW_W / 2 + trans[0], WINDOW_H / 4 + trans[1])\n",
    "\n",
    "        self._render_road(zoom, trans, angle)\n",
    "        self.car.draw(\n",
    "            self.surf,\n",
    "            zoom,\n",
    "            trans,\n",
    "            angle,\n",
    "            mode not in [\"state_pixels_list\", \"state_pixels\"],\n",
    "        )\n",
    "\n",
    "        self.surf = pygame.transform.flip(self.surf, False, True)\n",
    "\n",
    "        # showing stats\n",
    "        self._render_indicators(WINDOW_W, WINDOW_H)\n",
    "\n",
    "        font = pygame.font.Font(pygame.font.get_default_font(), 42)\n",
    "        text = font.render(\"%04i\" % self.reward, True, (255, 255, 255), (0, 0, 0))\n",
    "        text_rect = text.get_rect()\n",
    "        text_rect.center = (60, WINDOW_H - WINDOW_H * 2.5 / 40.0)\n",
    "        self.surf.blit(text, text_rect)\n",
    "\n",
    "        if mode == \"human\":\n",
    "            pygame.event.pump()\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "            assert self.screen is not None\n",
    "            self.screen.fill(0)\n",
    "            self.screen.blit(self.surf, (0, 0))\n",
    "            pygame.display.flip()\n",
    "\n",
    "        if mode == \"rgb_array\":\n",
    "            return self._create_image_array(self.surf, (VIDEO_W, VIDEO_H))\n",
    "        elif mode == \"state_pixels\":\n",
    "            return self._create_image_array(self.surf, (STATE_W, STATE_H))\n",
    "        else:\n",
    "            return self.isopen\n",
    "\n",
    "    def _render_road(self, zoom, translation, angle):\n",
    "        bounds = PLAYFIELD\n",
    "        field = [\n",
    "            (bounds, bounds),\n",
    "            (bounds, -bounds),\n",
    "            (-bounds, -bounds),\n",
    "            (-bounds, bounds),\n",
    "        ]\n",
    "\n",
    "        # draw background\n",
    "        self._draw_colored_polygon(\n",
    "            self.surf, field, self.bg_color, zoom, translation, angle, clip=False\n",
    "        )\n",
    "\n",
    "        # draw grass patches\n",
    "        grass = []\n",
    "        for x in range(-20, 20, 2):\n",
    "            for y in range(-20, 20, 2):\n",
    "                grass.append(\n",
    "                    [\n",
    "                        (GRASS_DIM * x + GRASS_DIM, GRASS_DIM * y + 0),\n",
    "                        (GRASS_DIM * x + 0, GRASS_DIM * y + 0),\n",
    "                        (GRASS_DIM * x + 0, GRASS_DIM * y + GRASS_DIM),\n",
    "                        (GRASS_DIM * x + GRASS_DIM, GRASS_DIM * y + GRASS_DIM),\n",
    "                    ]\n",
    "                )\n",
    "        for poly in grass:\n",
    "            self._draw_colored_polygon(\n",
    "                self.surf, poly, self.grass_color, zoom, translation, angle\n",
    "            )\n",
    "\n",
    "        # draw road\n",
    "        for poly, color in self.road_poly:\n",
    "            # converting to pixel coordinates\n",
    "            poly = [(p[0], p[1]) for p in poly]\n",
    "            color = [int(c) for c in color]\n",
    "            self._draw_colored_polygon(self.surf, poly, color, zoom, translation, angle)\n",
    "\n",
    "    def _render_indicators(self, W, H):\n",
    "        s = W / 40.0\n",
    "        h = H / 40.0\n",
    "        color = (0, 0, 0)\n",
    "        polygon = [(W, H), (W, H - 5 * h), (0, H - 5 * h), (0, H)]\n",
    "        pygame.draw.polygon(self.surf, color=color, points=polygon)\n",
    "\n",
    "        def vertical_ind(place, val):\n",
    "            return [\n",
    "                (place * s, H - (h + h * val)),\n",
    "                ((place + 1) * s, H - (h + h * val)),\n",
    "                ((place + 1) * s, H - h),\n",
    "                ((place + 0) * s, H - h),\n",
    "            ]\n",
    "\n",
    "        def horiz_ind(place, val):\n",
    "            return [\n",
    "                ((place + 0) * s, H - 4 * h),\n",
    "                ((place + val) * s, H - 4 * h),\n",
    "                ((place + val) * s, H - 2 * h),\n",
    "                ((place + 0) * s, H - 2 * h),\n",
    "            ]\n",
    "\n",
    "        assert self.car is not None\n",
    "        true_speed = np.sqrt(\n",
    "            np.square(self.car.hull.linearVelocity[0])\n",
    "            + np.square(self.car.hull.linearVelocity[1])\n",
    "        )\n",
    "\n",
    "        # simple wrapper to render if the indicator value is above a threshold\n",
    "        def render_if_min(value, points, color):\n",
    "            if abs(value) > 1e-4:\n",
    "                pygame.draw.polygon(self.surf, points=points, color=color)\n",
    "\n",
    "        render_if_min(true_speed, vertical_ind(5, 0.02 * true_speed), (255, 255, 255))\n",
    "        # ABS sensors\n",
    "        render_if_min(\n",
    "            self.car.wheels[0].omega,\n",
    "            vertical_ind(7, 0.01 * self.car.wheels[0].omega),\n",
    "            (0, 0, 255),\n",
    "        )\n",
    "        render_if_min(\n",
    "            self.car.wheels[1].omega,\n",
    "            vertical_ind(8, 0.01 * self.car.wheels[1].omega),\n",
    "            (0, 0, 255),\n",
    "        )\n",
    "        render_if_min(\n",
    "            self.car.wheels[2].omega,\n",
    "            vertical_ind(9, 0.01 * self.car.wheels[2].omega),\n",
    "            (51, 0, 255),\n",
    "        )\n",
    "        render_if_min(\n",
    "            self.car.wheels[3].omega,\n",
    "            vertical_ind(10, 0.01 * self.car.wheels[3].omega),\n",
    "            (51, 0, 255),\n",
    "        )\n",
    "\n",
    "        render_if_min(\n",
    "            self.car.wheels[0].joint.angle,\n",
    "            horiz_ind(20, -10.0 * self.car.wheels[0].joint.angle),\n",
    "            (0, 255, 0),\n",
    "        )\n",
    "        render_if_min(\n",
    "            self.car.hull.angularVelocity,\n",
    "            horiz_ind(30, -0.8 * self.car.hull.angularVelocity),\n",
    "            (255, 0, 0),\n",
    "        )\n",
    "\n",
    "    def _draw_colored_polygon(\n",
    "        self, surface, poly, color, zoom, translation, angle, clip=True\n",
    "    ):\n",
    "        poly = [pygame.math.Vector2(c).rotate_rad(angle) for c in poly]\n",
    "        poly = [\n",
    "            (c[0] * zoom + translation[0], c[1] * zoom + translation[1]) for c in poly\n",
    "        ]\n",
    "        # This checks if the polygon is out of bounds of the screen, and we skip drawing if so.\n",
    "        # Instead of calculating exactly if the polygon and screen overlap,\n",
    "        # we simply check if the polygon is in a larger bounding box whose dimension\n",
    "        # is greater than the screen by MAX_SHAPE_DIM, which is the maximum\n",
    "        # diagonal length of an environment object\n",
    "        if not clip or any(\n",
    "            (-MAX_SHAPE_DIM <= coord[0] <= WINDOW_W + MAX_SHAPE_DIM)\n",
    "            and (-MAX_SHAPE_DIM <= coord[1] <= WINDOW_H + MAX_SHAPE_DIM)\n",
    "            for coord in poly\n",
    "        ):\n",
    "            gfxdraw.aapolygon(self.surf, poly, color)\n",
    "            gfxdraw.filled_polygon(self.surf, poly, color)\n",
    "\n",
    "    def _create_image_array(self, screen, size):\n",
    "        scaled_screen = pygame.transform.smoothscale(screen, size)\n",
    "        return np.transpose(\n",
    "            np.array(pygame.surfarray.pixels3d(scaled_screen)), axes=(1, 0, 2)\n",
    "        )\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            pygame.display.quit()\n",
    "            self.isopen = False\n",
    "            pygame.quit()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    a = np.array([0.0, 0.0, 0.0])\n",
    "    frames = []\n",
    "    controls = []\n",
    "\n",
    "    def save_training_data(frames, controls):\n",
    "       np.savez_compressed('training_data.npz', frames=frames, controls=controls)\n",
    "\n",
    "    def register_input():\n",
    "        global quit, restart\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.KEYDOWN:\n",
    "\n",
    "                if event.key == pygame.K_LEFT:\n",
    "                    a[0] = -1.0\n",
    "                if event.key == pygame.K_RIGHT:\n",
    "                    a[0] = +1.0\n",
    "                if event.key == pygame.K_UP:\n",
    "                    a[1] = +1.0\n",
    "                if event.key == pygame.K_DOWN:\n",
    "                    a[2] = +0.8\n",
    "                \n",
    "                if event.key == pygame.K_RETURN:\n",
    "                    restart = True\n",
    "                if event.key == pygame.K_ESCAPE:\n",
    "                    quit = True\n",
    "\n",
    "            \n",
    "\n",
    "            if event.type == pygame.QUIT:\n",
    "                quit = True\n",
    "\n",
    "    def decode(prediction):\n",
    "        a = np.array([0.0, 0, 0.0])\n",
    "\n",
    "        if np.array_equal(prediction, [1,0,0,0,0]):   # for up \n",
    "            a = [0, +0.5, 0]\n",
    "\n",
    "        elif np.array_equal(prediction,[0,1,0,0,0]):   # for down \n",
    "            a = [0, 0, +0.8]\n",
    "\n",
    "        elif np.array_equal(prediction, [0,0,1,0,0]):   # for left \n",
    "            a = [-0.8, 0, 0]\n",
    "\n",
    "        elif np.array_equal(prediction,[0,0,0,1,0]):   # for right \n",
    "            a = [+0.8, 0, 0]\n",
    "\n",
    "        elif np.array_equal(prediction, [0,0,0,0,1]):   # for nothing \n",
    "            a = [0, 0, 0]\n",
    "        return np.array(a)\n",
    "\n",
    "    env = CarRacing(render_mode=\"human\")\n",
    "\n",
    "    quit = False\n",
    "    while not quit:\n",
    "        env.reset()\n",
    "        total_reward = 0.0\n",
    "        steps = 0\n",
    "        restart = False\n",
    "        to_tensor = transforms.ToTensor()\n",
    "        #a = [0, +1, 0]\n",
    "        s, r, terminated, truncated, info = env.step(None)\n",
    "        s = to_tensor(s).unsqueeze(0)\n",
    "        prediction = model(s)\n",
    "        max_index = torch.argmax(prediction)\n",
    "\n",
    "        # Step 2: Create a list with 1 at max_index and 0 elsewhere\n",
    "        prediction = [1 if i == max_index else 0 for i in range(prediction.size(1))]        \n",
    "        a =decode(prediction)\n",
    "        while True:\n",
    "            register_input()\n",
    "            print(prediction)\n",
    "            s, r, terminated, truncated, info = env.step(decode(prediction))\n",
    "            s = to_tensor(s).unsqueeze(0)\n",
    "            \n",
    "            prediction = model(s)\n",
    "            max_index = torch.argmax(prediction)\n",
    "\n",
    "            # Step 2: Create a list with 1 at max_index and 0 elsewhere\n",
    "            prediction = [1 if i == max_index else 0 for i in range(prediction.size(1))]\n",
    "            \n",
    "            a = decode(prediction)\n",
    "\n",
    "            #label = decode(a)\n",
    "            #frames.append(s)\n",
    "            #controls.append(label)\n",
    "            print(a)\n",
    "            \n",
    "            \n",
    "            total_reward += r\n",
    "            if steps % 200 == 0 or terminated or truncated:\n",
    "                print(\"\\naction \" + str([f\"{x:+0.2f}\" for x in a]))\n",
    "                print(f\"step {steps} total_reward {total_reward:+0.2f}\")\n",
    "            steps += 1\n",
    "            if terminated or truncated or restart or quit:\n",
    "                break\n",
    "\n",
    "            if len(frames) >= 5000:\n",
    "                break\n",
    "\n",
    "       \n",
    "        \n",
    "        if  len(frames) >= 5000:\n",
    "\n",
    "            #save_training_data(frames, controls)\n",
    "            quit = True \n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\MLSP\\Lab\\venv\\lib\\site-packages\\matplotlib\\text.py:1279: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '[0. 0. 0.]')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmHklEQVR4nO3df3BU1f3/8dcmIZtgfvBLNqQSiA7fooAjgkCEsa2m8lXbSkWrM1DxR7XVoAZmVKKF1loM2hml+kUsjsXfUunUn59Wa4PiWEEgGgu1Ah1tyVdIqF8ly88Esuf7R9sl9wAJm/1x7u4+HzN3Zs+9d++e3N3se89533tOwBhjBABAiuW4rgAAIDsRgAAAThCAAABOEIAAAE4QgAAAThCAAABOEIAAAE4QgAAAThCAAABOEICQVa666ioFAgEFAgGNHj3adXVSrqmpKfr3BwIB/fa3v3VdJWQxAhCyzqBBg/TUU09p0aJFR2x79913NWXKFPXt21dlZWW6+eabtWfPnrhez0/HHDZsmJ566indcccdcb0+kAgEIGSdE044QTNnztS3vvUtz/qmpiadd9552rdvn+6//3794Ac/0LJly3TZZZf1+rX8dsz+/ftr5syZ+uY3v9nr1wcSJc91BQC/uOOOO9S/f3+99dZbKikpkSQNHz5c1113nf74xz/q/PPPz9hjAi7QAgIkhcNhvfHGG5o5c2b0S12SrrzyShUVFen555/P2GMCrhCAAEkbN27UoUOHNH78eM/6/Px8nXHGGfrggw8y9piAKwQgQNKOHTskSUOGDDli25AhQ7R9+/aMPSbgCgEIkLR//35JUjAYPGJbQUFBdHsmHhNwhQAESCosLJQktbe3H7HtwIED0e2ZeEzAFQIQoMNdWv/t4upqx44dKi8vz9hjAq4QgABJo0ePVl5enjZs2OBZ39HRoaamJp1xxhkZe0zAFQIQIKm0tFTV1dV6+umntXv37uj6p556Snv27PHc5Llv3z59/PHH+vzzzzPimIAzBsgis2bNMsOGDTvqtsbGRhMMBs3YsWPN0qVLzZ133mkKCgrM+eef79nvzTffNJLMT37ykx5fz6/H/O+2lStX9vh6QLLQAgL+48wzz9Sf/vQnFRYWas6cOVq2bJmuvfbauAbsTJdjAi4EjDHGdSWAVLnqqqu0atUqvf/++8rLy1O/fv1cVymlOjs79eWXX+rPf/6zpk2bppUrV+rSSy91XS1kKcaCQ9Zpbm7WiSeeqFGjRmnTpk2uq5NSGzdu1NixY11XA5BECwhZ5qOPPoqOFlBUVKRJkyY5rlFq7dmzR2vXro2WTz/9dA0ePNhhjZDNCEAAACe4CAEA4AQBCADgRNIC0JIlSzR8+HAVFBRo4sSJWrduXbJeCgCQhpKSA/rNb36jK6+8Uo888ogmTpyoxYsXa+XKldq8eXOPCc9IJKLt27eruLhYgUAg0VUDACSZMUa7d+9WeXm5cnK6aeck4+7WCRMmmJqammi5s7PTlJeXm/r6+h6f29zcbCSxsLCwsKT50tzc3O33fcLvA+ro6FBjY6Pq6uqi63JyclRdXa01a9YcsX97e7tnaHnznwbZFeuvUH5RfqKrlzmMVW7tYTuOkLfa+/EP/F9a3LHq/N+dnnJkYMRRTeAnHXs7tOLbK1RcXNztfgkPQJ9//rk6OzsVCoU860OhkD7++OMj9q+vr9ddd911xPr8onzlFxOAjskOMHt72I4j5BVYASifABSrzr5WACoiAOGwntIozq+Cq6urU1tbW3Rpbm52XaX00GEtduMXPTtkLYiZCRrPAsQi4S2gQYMGKTc3V62t3j6h1tZWlZWVHbF/MBg86vTCAIDMlvAWUH5+vsaNG6eGhoboukgkooaGBlVVVSX65QAAaSopg5HOnTtXs2bN0vjx4zVhwgQtXrxYe/fu1dVXX52MlwMApKGkBKDLL79c//rXv7RgwQK1tLTojDPO0GuvvXbEhQmIQ4frCmQA8j7x+4pVtvtU9lnlg0msC9JO0qZjmD17tmbPnp2swwMA0pzzq+AAANmJAAQAcIIZUdMVOaC4mYh130qMt7Fk5ViF9k/WAqvcxyqfYJXtvFvXHNF+a1unkOFoAQEAnCAAAQCcoAsuXdjdQ3TBxc10eE/qEV1yDiWzey+uY1s/WU2fGM+Z/Y1TcozHknTAKttddPZ2/7x9OE60gAAAThCAAABOEIAAAE6QA0oX9hAm9HfHz8dD8fx3YkbfHTuV0/3Yl3jbZbsudo6o6yXeDAHkS7SAAABOEIAAAE4QgAAATpADShfc95N4DPUSO3uoHZfsn8/2sD9dy3usbeHEVwexowUEAHCCAAQAcIIABABwghxQuiAHlHic09jlu65AL5Hv8yVaQAAAJwhAAAAnCEAAACfIAaUL8hXxs4dAYzy92KXrT1b+f3wpXT9OAIA0RwACADhBAAIAOEEOyM+6zmGSynlYMlTgUMC7gnMau3T6ydr1/WU+IF9Kp48TACCDEIAAAE4QgAAATpAD8jPuXUgsK+djIom7ESgQCPS8UyYIuq5ADPj/8T1aQAAAJwhAAAAn6ILzs3bXFcgspsPqckvgUDzGuBvXJ6Xdf+n0k5UuON9Lp48TACCDEIAAAE4QgAAATvg3B2R0uI8+S65wPQJ92ImVodMypzT/lE4/Wfn/8b10+jgBADIIAQgA4AQBCADghH9zQDsl7fvP40JrW1+r3Cf51UmJQ1aZ6QISiyH541fgugLdsFNhvN++RwsIAOAEAQgA4AQBCADghH9zQBEdzoHstbbZ5a45oJ7yRX4Oudy3kFzkBOKXTv8/7obnw3Hy88cJAJDBCEAAACcIQAAAJ/ybA4rFwWM8lqTdVtmeUtjOEbm8z4H5f5IrQ8eCSyk7x+on5FDTDi0gAIATBCAAgBMEIACAE5mRA+qOfS/AgR7KuVa5u/uKEn326MNOLnJs8bP/P/yE/5+0QwsIAOAEAQgA4AQBCADgRObngGJl3yuyp5tyvrWtp3HoAj28FvepJFVOwPt7K7dP9wkNY45/MLFY9k32/rEeOyb2fXR+Qg4o7dACAgA4QQACADhBF1w87Ca/XQ5bZXuYH8J/SgUO2X2gPewfOP79Y9nX77rrwovke+eJj7icN57pF9IeX4EAACcIQAAAJwhAAAAnyAElk90nvd9JLfBfh1xXID10l88K5Pso18Vl12mPFhAAwAkCEADAiZgCUH19vc466ywVFxdr8ODBmjZtmjZv3uzZ58CBA6qpqdHAgQNVVFSk6dOnq7W1NaGVBgCkv5gC0OrVq1VTU6O1a9fqjTfe0MGDB3X++edr79690X3mzJmjV155RStXrtTq1au1fft2XXLJJQmvOIDUM0HjWZxqtxaknZguQnjttdc85ccff1yDBw9WY2OjzjnnHLW1temxxx7Ts88+q3PPPVeStHz5cp166qlau3atJk2alLiaAwDSWlw5oLa2NknSgAEDJEmNjY06ePCgqquro/uMHDlSFRUVWrNmzVGP0d7ernA47FkAAJmv1wEoEomotrZWkydP1ujRoyVJLS0tys/PV79+/Tz7hkIhtbS0HPU49fX1Ki0tjS5Dhw7tbZUAAGmk1wGopqZGmzZt0ooVK+KqQF1dndra2qJLc3NzXMcDjqnTWhC7XGtx6aC1wK1efDZ6dSPq7Nmz9eqrr+rtt9/WSSedFF1fVlamjo4O7dq1y9MKam1tVVlZ2VGPFQwGFQz6eZIRAEAyxNQCMsZo9uzZeuGFF7Rq1SpVVlZ6to8bN059+vRRQ0NDdN3mzZu1bds2VVVVJabGAICMEFMLqKamRs8++6xeeuklFRcXR/M6paWlKiwsVGlpqa699lrNnTtXAwYMUElJiW666SZVVVVxBRwAwCOmALR06VJJ0te//nXP+uXLl+uqq66SJD3wwAPKycnR9OnT1d7erqlTp+rhhx9OSGWBuJAniJ89p1Uq2e+fw6mIcBT5x3jcjZgC0PHMNV9QUKAlS5ZoyZIlsRwaAJBlGAsOAOAEAQgA4ATzASF7OB66LCO4/MnK/D/+1oscEC0gAIATBCAAgBN0wSFrmEPePrjOzu7H4+luaupYJfJYTl+rMHmH7hFdcP7WdUCb43yvaAEBAJwgAAEAnCAAAQCcIAeE7HEgtt2PZ+QPF8dKJTufZAIO/w5yQP5iN1/yjvE4hkMAAJASBCAAgBMEIACAE+SAkD3SMw3j1BG5q1T+ZD1klZlG3V+Oc7id7tACAgA4QQACADhBAAIAOEEOCNmD+0jiF+x5l4Th/fK3BHwWaAEBAJwgAAEAnCAAAQCcIAeE7MF9JPHLTeFrkQPyN+4DAgCkKwIQAMAJAhAAwAlyQMge5BTSS7vrCsDDbq70SfwhAQBICQIQAMAJAhAAwAlyQMge3AcUv2SOBWe/P7xf/pKAnI+NFhAAwAkCEADACbrgkDUiHRFrRXzHCwQC8R0gSZJZL5OXxHnNuUze3xIw9I6NFhAAwAkCEADACQIQAMAJckDIHgcTezhjkpgPiUNS65XMtBdD7/hbEi7BpwUEAHCCAAQAcIIABABwghwQskec9/1kpb4pfC3uA/Kfrjk/huIBAGQKAhAAwAkCEADACXJAyFx2zifB9wFlhdwkH7/re8T0C/7TNe+ThHvAaAEBAJwgAAEAnCAAAQCcIAeEzGUPiebPodv8zb73wx6vLd7xwbre+8P74z9JmAOoK1pAAAAnCEAAACcIQAAAJ8gBIXMxv0z87J+o/88q2/cJFVpleyw5+xuH98jfkjAHUFe0gAAAThCAAABOEIAAAE6QA0LGCkS8g1fl5Hb/e8uY3t+IEs9zE/H8pOnpG8Iev22PVd5rle37ihj/zV/s8d64DwgAkIkIQAAAJ+iCQ8YKHLS64HLS9/dWKrsHPftbl+FGYp3X3H5ppt32NzsiJGEKhq7S9z8SAJDWCEAAACcIQAAAJ8gBIXMdcl2BxAkEet8ZH89zTZ43iRNzDgjpJclD79hoAQEAnCAAAQCciCsALVq0SIFAQLW1tdF1Bw4cUE1NjQYOHKiioiJNnz5dra2t8dYTAJBheh2A1q9fr1/96lc6/fTTPevnzJmjV155RStXrtTq1au1fft2XXLJJXFXFIhZp7UgdkFrQWbLt5Yk61UA2rNnj2bMmKFHH31U/fv3j65va2vTY489pvvvv1/nnnuuxo0bp+XLl+vdd9/V2rVrE1ZpAED661UAqqmp0UUXXaTq6mrP+sbGRh08eNCzfuTIkaqoqNCaNWuOeqz29naFw2HPAgDIfDFfhr1ixQq9//77Wr9+/RHbWlpalJ+fr379+nnWh0IhtbS0HPV49fX1uuuuu2KtBgAgzcXUAmpubtYtt9yiZ555RgUFBQmpQF1dndra2qJLc3NzQo4LqMNaEDMTMJ4FGc7POaDGxkbt3LlTZ555pvLy8pSXl6fVq1frwQcfVF5enkKhkDo6OrRr1y7P81pbW1VWVnbUYwaDQZWUlHgWAEDmi6kL7rzzztPGjRs9666++mqNHDlSt99+u4YOHao+ffqooaFB06dPlyRt3rxZ27ZtU1VVVeJqDQBIezEFoOLiYo0ePdqz7oQTTtDAgQOj66+99lrNnTtXAwYMUElJiW666SZVVVVp0qRJias1ACDtJXwsuAceeEA5OTmaPn262tvbNXXqVD388MOJfhmgZwxbFr8U5AHgkB0BUjw2TtwB6K233vKUCwoKtGTJEi1ZsiTeQwMAMhhjwQEAnCAAAQCcYD4gZC7u/YlfrusKIKkc5/hoAQEAnCAAAQCcIAABAJwgB4TMZc0BFIl4bwwKBAIpq0oqXyuh+riuAJLK8RxPtIAAAE4QgAAATtAFh4xlOq3pA+yiSZ/pBZLZhdfdsU1e+pwj9AKXYQMAshEBCADgBAEIAOCEf3NAQR2+RNAeUoVuaRyPDBqKJ5n5qu6OnU55MhwHe2glx00QWkAAACcIQAAAJwhAAAAn/JsDGiCp+D+PrSFVtN8q7+vy+FDSagRkH4biySz2d2mrVS60yn27PE7CZ4EWEADACQIQAMAJAhAAwAn/5oC6sq9dL+qmbN/7sc8qH7DKESFT8d7GLz2+IdBb9v/I3m7K9mehbzfl4/zfowUEAHCCAAQAcIIABABwIvN6eO35LeyyPbSVnRPa1cP+SBuBjjSdBttPOIX4L/sey7BV3t3l8Z7jOyQtIACAEwQgAIATBCAAgBOZlwPqid2n3VOOCOmL+4DiZ9+DBxyLOcbjbtACAgA4QQACADhBAAIAOJF9OSCbPXYcMkak05sEChh3N7UEAml6Qw3fEEgiWkAAACcIQAAAJ2hg0wWXudq9RWPcXWOfytdOaHcfP1GRRHy8AABOEIAAAE4QgAAATpADau95F6SpLB2KJ6H5Jr4hkES0gAAAThCAAABOEIAAAE5kXw+vnRfodFILpAL3eMWvj+sKIJPRAgIAOEEAAgA4QQACADiRfTkgOy/AFNyZK0vvA0oopuRGEtECAgA4QQACADhBAAIAOEEOCJmL9zp++a4rgExGCwgA4AQBCADgBAEIAOBE9uWAmP8nawQ6A9aK2J6f0Hl10knX88RPVCQRHy8AgBMEIACAEwQgAIATmZ8DsrvxDzmpBY6lp7xMHGmYPPvjneBPeyw5onjzSSl9rbwuz2csOCQRLSAAgBMEIACAE5nfBcf0C/5WYJWLrfJ+q7zPKnc3pXqSh+IJBI7/uu5Y9nWuy/A7B3XQXT2Q8WgBAQCcIAABAJyIOQB99tlnmjlzpgYOHKjCwkKNGTNGGzZsiG43xmjBggUaMmSICgsLVV1dra1btya00gCA9BdTDujLL7/U5MmT9Y1vfEN/+MMfdOKJJ2rr1q3q379/dJ/77rtPDz74oJ544glVVlZq/vz5mjp1qj766CMVFNgd/inAkPz+Zg/3b38i7ZyQXbaHVtobd43AFAxIkZgC0L333quhQ4dq+fLl0XWVlZXRx8YYLV68WD/+8Y918cUXS5KefPJJhUIhvfjii7riiisSVG0AQLqLqQvu5Zdf1vjx43XZZZdp8ODBGjt2rB599NHo9k8//VQtLS2qrq6OristLdXEiRO1Zs2aox6zvb1d4XDYswAAMl9MAeiTTz7R0qVLNWLECL3++uu64YYbdPPNN+uJJ56QJLW0tEiSQqGQ53mhUCi6zVZfX6/S0tLoMnTo0N78HQCANBNTF1wkEtH48eN1zz33SJLGjh2rTZs26ZFHHtGsWbN6VYG6ujrNnTs3Wg6Hw4kNQky/4G/x5huC3mLAdLnfhnu+eofhd5AiMbWAhgwZotNOO82z7tRTT9W2bdskSWVlZZKk1tZWzz6tra3RbbZgMKiSkhLPAgDIfDEFoMmTJ2vz5s2edVu2bNGwYcMk/fuChLKyMjU0NES3h8Nhvffee6qqqkpAdQEAmSKmLrg5c+bo7LPP1j333KPvfe97WrdunZYtW6Zly5ZJ+vdwI7W1tfr5z3+uESNGRC/DLi8v17Rp05JRfwBAmoopAJ111ll64YUXVFdXp5/97GeqrKzU4sWLNWPGjOg+t912m/bu3avrr79eu3bt0pQpU/Taa6+l7h4gu9+foaz8xW5z90nw8SNdHpMD6p3MHyESPhEwPpv4PhwOq7S0VFf+7UrlF/ciQ23/NfbFd776a7OQHYCOnhrstcC+wxch5D3AN2mvDDz88OB3+AWH2HXs6dCT5z6ptra2bvP6jAUHAHCCAAQAcCLz+ijsHgO63Pwl2eOMcd9X3Ewf/mmQGrSAAABOEIAAAE4QgAAATmReDogcgL8lOwd06PDDWO8wCAQCPe+UDfhZihThowYAcIIABABwggAEAHAi83JAHa4rgG4lOQdkDh3O+xw6dKibPeMXT84o1ufGsn/cuaxk5+mA/6AFBABwggAEAHCCLjgkX9ceoWR376Tw/e/uMu/ScNhTzolEjrHnv0VyvL8F21zODMxIPEgRWkAAACcIQAAAJwhAAAAnMiMH1HUKBvqv/SeVl/V2pvC1urAv+R7zP//jKZ/c2X3FPsnN9ZTfuuwyTzkvL4X/qsHUvRSyGy0gAIATBCAAgBMEIACAE5mRA2IKBn9LZQ6o+9ttkubLL7/0lOcVF3vK9QMGdPv8ui++8JQnWsc78cQT46hdjPhZihThowYAcIIABABwggAEAHAiM3JAjP/mb6nMAR3seZdksKdAyLXu6wl2dP8htfd3Oj14H3cvjexCCwgA4AQBCADgBAEIAOAEOSAknp2+SGUOyNFnYdCgQZ7yBRdc4Cnn/ulP3T7f3t8pckBIEVpAAAAnCEAAACcIQAAAJ9IzB2Tf6+Fo/C8cg51DSOUtLT6ZD6p4zx5PuXzHjpj2311UlPA6HbfcnncBEoEWEADACQIQAMCJ9OyC47Jrf0vlZdc2n0zNMbapyVMOtndfMXv/t6dMSXCNYuDy/UNWoQUEAHCCAAQAcIIABABwghwQEi/o8LUPOXztLg72iW08m1j3TyqHM0Egu9ACAgA4QQACADhBAAIAOEEOCPGzcwYu0xmOPhtffPGFp/xQS4un/EgPU2zb+59sHW/AgAFx1C5GLnN4yCq0gAAAThCAAABOEIAAAE6kRw7Ivrej00ktcCz2p8jlzxpHOaDOTu+HsmLfPk95f9++3T7f3t8+XkoxHQNShBYQAMAJAhAAwAkCEADAifTIAXHfj7/5af4YR6mT0tJST/l/nXyyp/yv3bu7ff6E4mJPeYt1vJTiZylShI8aAMAJAhAAwAkCEADACXJAiJ+fckD73bxsfr73JPxj4kRvOdbjxVed+Pjp/cwG9rewncc0qapI6tECAgA4QQACADhBAAIAOEEOCPHz0/wxEdcVyADdT12EROtnle35tOy8ZtdhAw9a29IsX0QLCADgBAEIAOCEf7vgIjrcncL0C/7ip+kXbAdcVyAD+PdbITPYXZw9XfZuz+TRtWxPVbPPKtvddz77LvXTVwcAIIsQgAAATsQUgDo7OzV//nxVVlaqsLBQp5xyiu6++24Zc/jSC2OMFixYoCFDhqiwsFDV1dXaunVrwisOAEhvMfX23nvvvVq6dKmeeOIJjRo1Shs2bNDVV1+t0tJS3XzzzZKk++67Tw8++KCeeOIJVVZWav78+Zo6dao++ugjFRQUHP+L7dXhvtI0u7Qw4/l5qBaf9XGnJfsyYCRWIv9/7G/wkh7Kdo7Uzhm1W+Ukf/fGFIDeffddXXzxxbroooskScOHD9dzzz2ndevWSfp362fx4sX68Y9/rIsvvliS9OSTTyoUCunFF1/UFVdckeDqAwDSVUxdcGeffbYaGhq0ZcsWSdKHH36od955RxdccIEk6dNPP1VLS4uqq6ujzyktLdXEiRO1Zs2aox6zvb1d4XDYswAAMl9MLaB58+YpHA5r5MiRys3NVWdnpxYuXKgZM2ZIklpaWiRJoVDI87xQKBTdZquvr9ddd93Vm7oDANJYTAHo+eef1zPPPKNnn31Wo0aNUlNTk2pra1VeXq5Zs2b1qgJ1dXWaO3dutBwOhzV06FBpT68Oh1Tw09A7NrsPG7FjKJ7kcplDtdPwdtkeyqrrfUR2vsgeBqgXYgpAt956q+bNmxfN5YwZM0b//Oc/VV9fr1mzZqmsrEyS1NraqiFDhkSf19raqjPOOOOoxwwGgwoG/fyNBgBIhphyQPv27VNOjvcpubm5ikT+HTYrKytVVlamhoaG6PZwOKz33ntPVVVVCaguACBTxNQC+va3v62FCxeqoqJCo0aN0gcffKD7779f11xzjSQpEAiotrZWP//5zzVixIjoZdjl5eWaNm1aMuoPAEhTMQWghx56SPPnz9eNN96onTt3qry8XD/84Q+1YMGC6D633Xab9u7dq+uvv167du3SlClT9Nprr8V2DxD8zc/3ASWgXzrr2P0g3AeUXH7+/7E/Cycc47F05P9a1xzRcd4/FDBdhzHwgXA4rNLSUl256krlF/n5ncpiIauc66QWR/d/ujz+3Fkt0ov9pXN1l8d+em8zxUCrnK4p8G4CUMeeDj058Um1tbWppMS+G/YwxoIDADhBAAIAOMHMH+iZ3Q3j524Ze34UxM7P7286inX+n3Rh5wpLuzw+zqYNLSAAgBMEIACAEwQgAIATvr0MGwCQ3rgMGwDgSwQgAIATBCAAgBMEIACAEwQgAIATBCAAgBMEIACAEwQgAIATBCAAgBMEIACAExkxHcMJJxyeK3bEiBGebU1NTZ5ybq53rPnOzk5PecKECZ7yX//6V0957969va0mAKALWkAAACcIQAAAJwhAAAAnMiIHVFdXF308ePBgz7YVK1Z4yrW1tZ7ynXfe6SlfeumlnvKFF17oKf/0pz/tZS0BAF3RAgIAOEEAAgA4QQACADiRFjmgvDxvNSdNmuQpFxUVRR///ve/92zLyfHG2ObmZk9548aNnvK6des85VAoFFtlAQDHhRYQAMAJAhAAwAkCEADAibTMAU2ZMsVT7prnOemkkzzbVq9e7Sm3t7d7yl/96lc95Z07d3rK55xzTmyVBQAcF1pAAAAnCEAAACcIQAAAJ9IiB3TgwAFPedGiRZ7yqFGjoo8vuOACz7ZNmzZ5ym+//ban/I9//MNTvvzyyz3lZcuWxVRXAMDxoQUEAHCCAAQAcIIABABwImCMMa4r0VU4HFZpaanragAA4tTW1qaSkpJjbqcFBABwggAEAHCCAAQAcIIABABwggAEAHCCAAQAcIIABABwggAEAHCCAAQAcIIABABwggAEAHCCAAQAcIIABABwwncByGeDcwMAeqmn73PfBaDdu3e7rgIAIAF6+j733XxAkUhE27dvlzFGFRUVam5u7nY+CRwWDoc1dOhQzlkMOGex45zFLtvOmTFGu3fvVnl5uXJyjt3OyUthnY5LTk6OTjrpJIXDYUlSSUlJVrxhicQ5ix3nLHacs9hl0zk7nolFfdcFBwDIDgQgAIATvg1AwWBQP/nJTxQMBl1XJW1wzmLHOYsd5yx2nLOj891FCACA7ODbFhAAILMRgAAAThCAAABOEIAAAE4QgAAATvg2AC1ZskTDhw9XQUGBJk6cqHXr1rmukm/U19frrLPOUnFxsQYPHqxp06Zp8+bNnn0OHDigmpoaDRw4UEVFRZo+fbpaW1sd1dhfFi1apEAgoNra2ug6zteRPvvsM82cOVMDBw5UYWGhxowZow0bNkS3G2O0YMECDRkyRIWFhaqurtbWrVsd1titzs5OzZ8/X5WVlSosLNQpp5yiu+++2zMgJ+fMYnxoxYoVJj8/3/z61782f/3rX811111n+vXrZ1pbW11XzRemTp1qli9fbjZt2mSamprMhRdeaCoqKsyePXui+/zoRz8yQ4cONQ0NDWbDhg1m0qRJ5uyzz3ZYa39Yt26dGT58uDn99NPNLbfcEl3P+fL64osvzLBhw8xVV11l3nvvPfPJJ5+Y119/3fz973+P7rNo0SJTWlpqXnzxRfPhhx+a73znO6aystLs37/fYc3dWbhwoRk4cKB59dVXzaeffmpWrlxpioqKzC9/+cvoPpwzL18GoAkTJpiamppoubOz05SXl5v6+nqHtfKvnTt3Gklm9erVxhhjdu3aZfr06WNWrlwZ3edvf/ubkWTWrFnjqprO7d6924wYMcK88cYb5mtf+1o0AHG+jnT77bebKVOmHHN7JBIxZWVl5he/+EV03a5du0wwGDTPPfdcKqroOxdddJG55pprPOsuueQSM2PGDGMM5+xofNcF19HRocbGRlVXV0fX5eTkqLq6WmvWrHFYM/9qa2uTJA0YMECS1NjYqIMHD3rO4ciRI1VRUZHV57CmpkYXXXSR57xInK+jefnllzV+/HhddtllGjx4sMaOHatHH300uv3TTz9VS0uL55yVlpZq4sSJWXvOzj77bDU0NGjLli2SpA8//FDvvPOOLrjgAkmcs6Px3WjYn3/+uTo7OxUKhTzrQ6GQPv74Y0e18q9IJKLa2lpNnjxZo0ePliS1tLQoPz9f/fr18+wbCoXU0tLioJburVixQu+//77Wr19/xDbO15E++eQTLV26VHPnztUdd9yh9evX6+abb1Z+fr5mzZoVPS9H+z/N1nM2b948hcNhjRw5Urm5uers7NTChQs1Y8YMSeKcHYXvAhBiU1NTo02bNumdd95xXRXfam5u1i233KI33nhDBQUFrquTFiKRiMaPH6977rlHkjR27Fht2rRJjzzyiGbNmuW4dv70/PPP65lnntGzzz6rUaNGqampSbW1tSovL+ecHYPvuuAGDRqk3NzcI65Aam1tVVlZmaNa+dPs2bP16quv6s0339RJJ50UXV9WVqaOjg7t2rXLs3+2nsPGxkbt3LlTZ555pvLy8pSXl6fVq1frwQcfVF5enkKhEOfLMmTIEJ122mmedaeeeqq2bdsmSdHzwv/pYbfeeqvmzZunK664QmPGjNH3v/99zZkzR/X19ZI4Z0fjuwCUn5+vcePGqaGhIbouEomooaFBVVVVDmvmH8YYzZ49Wy+88IJWrVqlyspKz/Zx48apT58+nnO4efNmbdu2LSvP4XnnnaeNGzeqqakpuowfP14zZsyIPuZ8eU2ePPmIS/u3bNmiYcOGSZIqKytVVlbmOWfhcFjvvfde1p6zffv2HTH7Z25uriKRiCTO2VG5vgriaFasWGGCwaB5/PHHzUcffWSuv/56069fP9PS0uK6ar5www03mNLSUvPWW2+ZHTt2RJd9+/ZF9/nRj35kKioqzKpVq8yGDRtMVVWVqaqqclhrf+l6FZwxnC/bunXrTF5enlm4cKHZunWreeaZZ0zfvn3N008/Hd1n0aJFpl+/fuall14yf/nLX8zFF1+c1ZcUz5o1y3zlK1+JXob9u9/9zgwaNMjcdttt0X04Z16+DEDGGPPQQw+ZiooKk5+fbyZMmGDWrl3rukq+Iemoy/Lly6P77N+/39x4442mf//+pm/fvua73/2u2bFjh7tK+4wdgDhfR3rllVfM6NGjTTAYNCNHjjTLli3zbI9EImb+/PkmFAqZYDBozjvvPLN582ZHtXUvHA6bW265xVRUVJiCggJz8sknmzvvvNO0t7dH9+GceTEfEADACd/lgAAA2YEABABwggAEAHCCAAQAcIIABABwggAEAHCCAAQAcIIABABwggAEAHCCAAQAcIIABABw4v8DRVxvIxw27YEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imu = s\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "imu = imu.permute(1, 2, 0).numpy() \n",
    "imu = (imu * 255).astype(np.uint8)\n",
    "\n",
    "plt.imshow(imu)\n",
    "plt.title(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example tensor output from your model\n",
    "tensor_output = torch.tensor([[-1.5919, -1.5907, -1.6207, -1.6176, -1.6269]])\n",
    "\n",
    "# Step 1: Get the index of the maximum value\n",
    "max_index = torch.argmax(tensor_output)\n",
    "\n",
    "# Step 2: Create a list with 1 at max_index and 0 elsewhere\n",
    "output_list = [1 if i == max_index else 0 for i in range(tensor_output.size(1))]\n",
    "\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n",
      "Number of CUDA devices: 1\n",
      "Current CUDA device: 0\n",
      "CUDA device name: NVIDIA GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Recurrent Neural Network Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, the goal is to change one of more hidden layers of the MLP with a recurrent layer such as [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html), [LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#lstm) or [GRU](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU). Instead of training a model that predicts the action independently from other images, we will train a model that keeps a state through the input frames. As a result, the proposed model action depends not only on the input frame but also on the past ones\n",
    "\n",
    " \n",
    "*Task Output*: The feed forward network should be replaced with a recurrent neural network (RNN). The number of cells can be freely chosen. Once the RNN is trained, it should be used for end-to-end driving as in the previous exercise. The output of the exercise is to launch the simulator and let the RNN perform the driving. This should be a live demo as well.\n",
    "\n",
    "*Important*: The scripts should be **self-contained**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
